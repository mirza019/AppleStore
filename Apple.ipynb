{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap= pd.read_csv('apst.csv',index_col=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>currency</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7192</td>\n",
       "      <td>1170406182</td>\n",
       "      <td>Shark Boom - Challenge Friends with your Pet</td>\n",
       "      <td>245415936</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0.9</td>\n",
       "      <td>4+</td>\n",
       "      <td>Games</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7193</td>\n",
       "      <td>1069830936</td>\n",
       "      <td>【謎解き】ヤミすぎ彼女からのメッセージ</td>\n",
       "      <td>16808960</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>9+</td>\n",
       "      <td>Book</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7194</td>\n",
       "      <td>1070052833</td>\n",
       "      <td>Go!Go!Cat!</td>\n",
       "      <td>91468800</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>12+</td>\n",
       "      <td>Games</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7195</td>\n",
       "      <td>1081295232</td>\n",
       "      <td>Suppin Detective: Expose their true visage!</td>\n",
       "      <td>83026944</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0.3</td>\n",
       "      <td>12+</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7196</td>\n",
       "      <td>977965019</td>\n",
       "      <td>みんなのお弁当 by クックパッド ~お弁当をレシピ付きで記録・共有~</td>\n",
       "      <td>51174400</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4.0</td>\n",
       "      <td>4+</td>\n",
       "      <td>Food &amp; Drink</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                    track_name  size_bytes  \\\n",
       "7192  1170406182  Shark Boom - Challenge Friends with your Pet   245415936   \n",
       "7193  1069830936                           【謎解き】ヤミすぎ彼女からのメッセージ    16808960   \n",
       "7194  1070052833                                    Go!Go!Cat!    91468800   \n",
       "7195  1081295232   Suppin Detective: Expose their true visage!    83026944   \n",
       "7196   977965019           みんなのお弁当 by クックパッド ~お弁当をレシピ付きで記録・共有~    51174400   \n",
       "\n",
       "     currency  price  rating_count_tot  rating_count_ver  user_rating  \\\n",
       "7192      USD    0.0                 0                 0          0.0   \n",
       "7193      USD    0.0                 0                 0          0.0   \n",
       "7194      USD    0.0                 0                 0          0.0   \n",
       "7195      USD    0.0                 0                 0          0.0   \n",
       "7196      USD    0.0                 0                 0          0.0   \n",
       "\n",
       "      user_rating_ver    ver cont_rating    prime_genre  sup_devices.num  \\\n",
       "7192              0.0  1.0.9          4+          Games               38   \n",
       "7193              0.0    1.2          9+           Book               38   \n",
       "7194              0.0  1.1.2         12+          Games               37   \n",
       "7195              0.0  1.0.3         12+  Entertainment               40   \n",
       "7196              0.0  1.4.0          4+   Food & Drink               37   \n",
       "\n",
       "      ipadSc_urls.num  lang.num  vpp_lic  \n",
       "7192                5         1        1  \n",
       "7193                0         1        1  \n",
       "7194                2         2        1  \n",
       "7195                0         1        1  \n",
       "7196                0         1        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap.drop(['id', 'track_name', 'size_bytes', 'currency', 'price',\n",
    "         'ver', 'cont_rating', 'prime_genre','vpp_lic'],axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating_count_tot', 'rating_count_ver', 'user_rating',\n",
       "       'user_rating_ver', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2974676</td>\n",
       "      <td>212</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2161558</td>\n",
       "      <td>1289</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2130805</td>\n",
       "      <td>579</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1724546</td>\n",
       "      <td>3842</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1126879</td>\n",
       "      <td>3594</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating_count_tot  rating_count_ver  user_rating  user_rating_ver  \\\n",
       "0           2974676               212          3.5              3.5   \n",
       "1           2161558              1289          4.5              4.0   \n",
       "2           2130805               579          4.5              4.5   \n",
       "3           1724546              3842          4.5              4.0   \n",
       "4           1126879              3594          4.0              4.5   \n",
       "\n",
       "   sup_devices.num  ipadSc_urls.num  lang.num  \n",
       "0               37                1        29  \n",
       "1               37                0        29  \n",
       "2               38                5        18  \n",
       "3               40                5         1  \n",
       "4               37                4         1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating_count_tot  rating_count_ver  user_rating  user_rating_ver  \\\n",
       "6997                 0                 0          0.0              0.0   \n",
       "6998                 0                 0          0.0              0.0   \n",
       "6999                 0                 0          0.0              0.0   \n",
       "7000                 0                 0          0.0              0.0   \n",
       "7001                 0                 0          0.0              0.0   \n",
       "...                ...               ...          ...              ...   \n",
       "7192                 0                 0          0.0              0.0   \n",
       "7193                 0                 0          0.0              0.0   \n",
       "7194                 0                 0          0.0              0.0   \n",
       "7195                 0                 0          0.0              0.0   \n",
       "7196                 0                 0          0.0              0.0   \n",
       "\n",
       "      sup_devices.num  ipadSc_urls.num  lang.num  \n",
       "6997               37                5         2  \n",
       "6998               40                4         2  \n",
       "6999               38                0         1  \n",
       "7000               40                4         1  \n",
       "7001               40                3         1  \n",
       "...               ...              ...       ...  \n",
       "7192               38                5         1  \n",
       "7193               38                0         1  \n",
       "7194               37                2         2  \n",
       "7195               40                0         1  \n",
       "7196               37                0         1  \n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.tail(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ap.drop('user_rating',axis =1)\n",
    "y = ap['user_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4580    4.0\n",
       "3088    4.5\n",
       "6241    3.0\n",
       "5553    1.5\n",
       "5022    4.0\n",
       "       ... \n",
       "1802    4.0\n",
       "2064    4.0\n",
       "5533    5.0\n",
       "6806    0.0\n",
       "3731    5.0\n",
       "Name: user_rating, Length: 2447, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsn = ap.sample(10)\n",
    "unsn_x = unsn.drop('user_rating',axis =1)\n",
    "unsn_y = unsn['user_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnrg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lnrg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmprediction = lnrg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearsons correlation: 0.776\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "lmcorr, _ = pearsonr(lmprediction, y_test)\n",
    "print('Pearsons correlation: %.3f' % lmcorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "lmmae=mean_absolute_error(y_test, lmprediction).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmmsqe=mean_squared_error(y_test, lmprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmrms = sqrt(mean_squared_error(y_test, lmprediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Coeefficient Correlation: 0.776\n",
      "Mean Absolute Error: 0.651\n",
      "Mean Squre Root Error: 0.940\n",
      "Root Mean Squre Error: 0.970\n"
     ]
    }
   ],
   "source": [
    "print('Linear Regression')\n",
    "print('Coeefficient Correlation: %.3f'%lmcorr)\n",
    "print('Mean Absolute Error: %.3f'%lmmae)\n",
    "print('Mean Squre Root Error: %.3f'%lmmsqe)\n",
    "print('Root Mean Squre Error: %.3f'%lmrms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cafeo\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "    gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_mdl = SVR()\n",
    "svc_mdl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsvm = svc_mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearsons correlation: 0.909\n"
     ]
    }
   ],
   "source": [
    "svmcorr, _ = pearsonr(predsvm, y_test)\n",
    "print('Pearsons correlation: %.3f' % svmcorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmmae=mean_absolute_error(y_test, predsvm).round(3)\n",
    "svmmsqe=mean_squared_error(y_test, predsvm)\n",
    "svmrms = sqrt(mean_squared_error(y_test, predsvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Coeefficient Correlation: 0.909\n",
      "Mean Absolute Error: 0.451\n",
      "Mean Squre Root Error: 0.413\n",
      "Root Mean Squre Error: 0.643\n"
     ]
    }
   ],
   "source": [
    "print('SVM')\n",
    "print('Coeefficient Correlation: %.3f'%svmcorr)\n",
    "print('Mean Absolute Error: %.3f'%svmmae)\n",
    "print('Mean Squre Root Error: %.3f'%svmmsqe)\n",
    "print('Root Mean Squre Error: %.3f'%svmrms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestRegressor(n_estimators=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train,y_train)\n",
    "predrf = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeefficient Correlation: 0.951\n",
      "Mean Absolute Error: 0.293\n",
      "Mean Squre Root Error: 0.227\n",
      "Root Mean Squre Error: 0.476\n"
     ]
    }
   ],
   "source": [
    "rfcorr, _ = pearsonr(predrf, y_test)\n",
    "rfmae=mean_absolute_error(y_test, predrf).round(3)\n",
    "rfmsqe=mean_squared_error(y_test, predrf)\n",
    "rfrms = sqrt(mean_squared_error(y_test, predrf))\n",
    "print('Coeefficient Correlation: %.3f'%rfcorr)\n",
    "print('Mean Absolute Error: %.3f'%rfmae)\n",
    "print('Mean Squre Root Error: %.3f'%rfmsqe)\n",
    "print('Root Mean Squre Error: %.3f'%rfrms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr.fit(X_train,y_train)\n",
    "predtr = dtr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Coeefficient Correlation: nan\n",
      "Mean Absolute Error: 0.359\n",
      "Mean Squre Root Error: 0.388\n",
      "Root Mean Squre Error: 0.623\n"
     ]
    }
   ],
   "source": [
    "dtrcorr, _ = pearsonr(predtr, y_test)\n",
    "dtrmae=mean_absolute_error(y_test, predtr).round(3)\n",
    "dtrmsqe=mean_squared_error(y_test, predtr)\n",
    "dtrrms = sqrt(mean_squared_error(y_test, predtr))\n",
    "print('Decision Tree')\n",
    "print('Coeefficient Correlation: %.3f'%dtrcorr)\n",
    "print('Mean Absolute Error: %.3f'%dtrmae)\n",
    "print('Mean Squre Root Error: %.3f'%dtrmsqe)\n",
    "print('Root Mean Squre Error: %.3f'%dtrrms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ap.drop('user_rating',axis =1).values\n",
    "y = ap['user_rating'].values\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=1),\n",
    "    Dense(units=1),\n",
    "    Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Dense(2))\n",
    "model.add(Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "\n",
    "# Final output node for prediction\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "4750/4750 [==============================] - 0s 96us/sample - loss: 19776.9720\n",
      "Epoch 2/250\n",
      "4750/4750 [==============================] - 0s 38us/sample - loss: 522.9457\n",
      "Epoch 3/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 52.6476\n",
      "Epoch 4/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 15.9865\n",
      "Epoch 5/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 12.5313\n",
      "Epoch 6/250\n",
      "4750/4750 [==============================] - 0s 43us/sample - loss: 14.8747\n",
      "Epoch 7/250\n",
      "4750/4750 [==============================] - 0s 40us/sample - loss: 10.1912\n",
      "Epoch 8/250\n",
      "4750/4750 [==============================] - 0s 42us/sample - loss: 8.4109\n",
      "Epoch 9/250\n",
      "4750/4750 [==============================] - 0s 42us/sample - loss: 11.7345\n",
      "Epoch 10/250\n",
      "4750/4750 [==============================] - 0s 52us/sample - loss: 5.8398\n",
      "Epoch 11/250\n",
      "4750/4750 [==============================] - 0s 50us/sample - loss: 4.6117\n",
      "Epoch 12/250\n",
      "4750/4750 [==============================] - 0s 41us/sample - loss: 3.7450\n",
      "Epoch 13/250\n",
      "4750/4750 [==============================] - 0s 39us/sample - loss: 3.5815\n",
      "Epoch 14/250\n",
      "4750/4750 [==============================] - 0s 39us/sample - loss: 3.5039\n",
      "Epoch 15/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 2.6285\n",
      "Epoch 16/250\n",
      "4750/4750 [==============================] - 0s 40us/sample - loss: 2.7689\n",
      "Epoch 17/250\n",
      "4750/4750 [==============================] - 0s 43us/sample - loss: 2.6883\n",
      "Epoch 18/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 2.5712\n",
      "Epoch 19/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.5455\n",
      "Epoch 20/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 2.9317\n",
      "Epoch 21/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 2.3430\n",
      "Epoch 22/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 2.6451\n",
      "Epoch 23/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 2.2431\n",
      "Epoch 24/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.3919\n",
      "Epoch 25/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 2.2544\n",
      "Epoch 26/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 2.3909\n",
      "Epoch 27/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 2.3898\n",
      "Epoch 28/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.3273\n",
      "Epoch 29/250\n",
      "4750/4750 [==============================] - 0s 36us/sample - loss: 2.9696\n",
      "Epoch 30/250\n",
      "4750/4750 [==============================] - 0s 37us/sample - loss: 2.1598\n",
      "Epoch 31/250\n",
      "4750/4750 [==============================] - 0s 38us/sample - loss: 2.3219\n",
      "Epoch 32/250\n",
      "4750/4750 [==============================] - 0s 36us/sample - loss: 2.2740\n",
      "Epoch 33/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 2.2872\n",
      "Epoch 34/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 2.1514\n",
      "Epoch 35/250\n",
      "4750/4750 [==============================] - 0s 51us/sample - loss: 2.1736\n",
      "Epoch 36/250\n",
      "4750/4750 [==============================] - 0s 42us/sample - loss: 2.3072\n",
      "Epoch 37/250\n",
      "4750/4750 [==============================] - 0s 49us/sample - loss: 2.1697\n",
      "Epoch 38/250\n",
      "4750/4750 [==============================] - 0s 43us/sample - loss: 2.1312\n",
      "Epoch 39/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 2.2205\n",
      "Epoch 40/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 2.9154\n",
      "Epoch 41/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.0783\n",
      "Epoch 42/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 2.5127\n",
      "Epoch 43/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.0984\n",
      "Epoch 44/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.2017\n",
      "Epoch 45/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.1703\n",
      "Epoch 46/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 2.0539\n",
      "Epoch 47/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 2.0689\n",
      "Epoch 48/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 2.3582\n",
      "Epoch 49/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 2.0942\n",
      "Epoch 50/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.0063\n",
      "Epoch 51/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.1134\n",
      "Epoch 52/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.0515\n",
      "Epoch 53/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 2.1567\n",
      "Epoch 54/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.1236\n",
      "Epoch 55/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 2.0563\n",
      "Epoch 56/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.9591\n",
      "Epoch 57/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 2.0143\n",
      "Epoch 58/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.9691\n",
      "Epoch 59/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 2.0814\n",
      "Epoch 60/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.9587\n",
      "Epoch 61/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.0704\n",
      "Epoch 62/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 2.2262\n",
      "Epoch 63/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.0039\n",
      "Epoch 64/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 2.5164\n",
      "Epoch 65/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 2.0185\n",
      "Epoch 66/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.9436\n",
      "Epoch 67/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 1.9231\n",
      "Epoch 68/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.9801\n",
      "Epoch 69/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 1.9255\n",
      "Epoch 70/250\n",
      "4750/4750 [==============================] - 0s 42us/sample - loss: 1.8698\n",
      "Epoch 71/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 1.8345\n",
      "Epoch 72/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.9309\n",
      "Epoch 73/250\n",
      "4750/4750 [==============================] - 0s 45us/sample - loss: 2.1660\n",
      "Epoch 74/250\n",
      "4750/4750 [==============================] - 0s 38us/sample - loss: 2.2254\n",
      "Epoch 75/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 2.60060s - loss: 2.599\n",
      "Epoch 76/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.8225\n",
      "Epoch 77/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.9293\n",
      "Epoch 78/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 2.0461\n",
      "Epoch 79/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.9582\n",
      "Epoch 80/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.9147\n",
      "Epoch 81/250\n",
      "4750/4750 [==============================] - 0s 36us/sample - loss: 1.8834\n",
      "Epoch 82/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.0318\n",
      "Epoch 83/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.8407\n",
      "Epoch 84/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 2.0118\n",
      "Epoch 85/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 1.8889\n",
      "Epoch 86/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.9826\n",
      "Epoch 87/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.8661\n",
      "Epoch 88/250\n",
      "4750/4750 [==============================] - 0s 39us/sample - loss: 2.1177\n",
      "Epoch 89/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 1.9645\n",
      "Epoch 90/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 2.0436\n",
      "Epoch 91/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.7650\n",
      "Epoch 92/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.7538\n",
      "Epoch 93/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750/4750 [==============================] - 0s 31us/sample - loss: 2.5154\n",
      "Epoch 94/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.6777\n",
      "Epoch 95/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 8.3012\n",
      "Epoch 96/250\n",
      "4750/4750 [==============================] - 0s 44us/sample - loss: 1.8254\n",
      "Epoch 97/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 1.8161\n",
      "Epoch 98/250\n",
      "4750/4750 [==============================] - 0s 29us/sample - loss: 2.3564\n",
      "Epoch 99/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.8442\n",
      "Epoch 100/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.8080\n",
      "Epoch 101/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 2.1202\n",
      "Epoch 102/250\n",
      "4750/4750 [==============================] - 0s 41us/sample - loss: 1.7353\n",
      "Epoch 103/250\n",
      "4750/4750 [==============================] - 0s 39us/sample - loss: 1.8694\n",
      "Epoch 104/250\n",
      "4750/4750 [==============================] - 0s 40us/sample - loss: 1.6552\n",
      "Epoch 105/250\n",
      "4750/4750 [==============================] - 0s 43us/sample - loss: 2.0144\n",
      "Epoch 106/250\n",
      "4750/4750 [==============================] - 0s 41us/sample - loss: 1.9053\n",
      "Epoch 107/250\n",
      "4750/4750 [==============================] - 0s 41us/sample - loss: 1.5891\n",
      "Epoch 108/250\n",
      "4750/4750 [==============================] - 0s 40us/sample - loss: 1.7530\n",
      "Epoch 109/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.7004\n",
      "Epoch 110/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 1.7032\n",
      "Epoch 111/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.9191\n",
      "Epoch 112/250\n",
      "4750/4750 [==============================] - 0s 41us/sample - loss: 1.5764\n",
      "Epoch 113/250\n",
      "4750/4750 [==============================] - 0s 45us/sample - loss: 1.8942\n",
      "Epoch 114/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 1.7197\n",
      "Epoch 115/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.7380\n",
      "Epoch 116/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 1.6985\n",
      "Epoch 117/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.6153\n",
      "Epoch 118/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 1.6467\n",
      "Epoch 119/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.6773\n",
      "Epoch 120/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 1.6882\n",
      "Epoch 121/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 2.6321\n",
      "Epoch 122/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.5820\n",
      "Epoch 123/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 3.5639\n",
      "Epoch 124/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 2.0025\n",
      "Epoch 125/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 2.3734\n",
      "Epoch 126/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.6415\n",
      "Epoch 127/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.4606\n",
      "Epoch 128/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 2.4088\n",
      "Epoch 129/250\n",
      "4750/4750 [==============================] - 0s 36us/sample - loss: 1.4332\n",
      "Epoch 130/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.5611\n",
      "Epoch 131/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.4522\n",
      "Epoch 132/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.7842\n",
      "Epoch 133/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.4861\n",
      "Epoch 134/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.4391\n",
      "Epoch 135/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 1.4380\n",
      "Epoch 136/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.7088\n",
      "Epoch 137/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.4457\n",
      "Epoch 138/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.4732\n",
      "Epoch 139/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.6386\n",
      "Epoch 140/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.5410\n",
      "Epoch 141/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 2.0814\n",
      "Epoch 142/250\n",
      "4750/4750 [==============================] - 0s 36us/sample - loss: 1.4288\n",
      "Epoch 143/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.6665\n",
      "Epoch 144/250\n",
      "4750/4750 [==============================] - 0s 41us/sample - loss: 1.8400\n",
      "Epoch 145/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.5101\n",
      "Epoch 146/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.5612\n",
      "Epoch 147/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.4165\n",
      "Epoch 148/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.3897\n",
      "Epoch 149/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.4804\n",
      "Epoch 150/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.5934\n",
      "Epoch 151/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.3296\n",
      "Epoch 152/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.5909\n",
      "Epoch 153/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.5410\n",
      "Epoch 154/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.3657\n",
      "Epoch 155/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.4186\n",
      "Epoch 156/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.5323\n",
      "Epoch 157/250\n",
      "4750/4750 [==============================] - ETA: 0s - loss: 1.358 - 0s 36us/sample - loss: 1.3431\n",
      "Epoch 158/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.6232\n",
      "Epoch 159/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.5003\n",
      "Epoch 160/250\n",
      "4750/4750 [==============================] - 0s 38us/sample - loss: 1.4499\n",
      "Epoch 161/250\n",
      "4750/4750 [==============================] - 0s 36us/sample - loss: 2.2951\n",
      "Epoch 162/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 1.4388\n",
      "Epoch 163/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.3268\n",
      "Epoch 164/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 1.5252\n",
      "Epoch 165/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.3843\n",
      "Epoch 166/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.3299\n",
      "Epoch 167/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 2.3060\n",
      "Epoch 168/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 1.3669\n",
      "Epoch 169/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.3538\n",
      "Epoch 170/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.2837\n",
      "Epoch 171/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.4208\n",
      "Epoch 172/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 1.5929\n",
      "Epoch 173/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.6069\n",
      "Epoch 174/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.4332\n",
      "Epoch 175/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 2.3707\n",
      "Epoch 176/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 1.3956\n",
      "Epoch 177/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.5030\n",
      "Epoch 178/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 2.1919\n",
      "Epoch 179/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 1.2622\n",
      "Epoch 180/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.2382\n",
      "Epoch 181/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 1.5722\n",
      "Epoch 182/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.2979\n",
      "Epoch 183/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.2551\n",
      "Epoch 184/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.4187\n",
      "Epoch 185/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.2614\n",
      "Epoch 186/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.3673\n",
      "Epoch 187/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.3651\n",
      "Epoch 188/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 3.9079\n",
      "Epoch 189/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.2169\n",
      "Epoch 190/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 2.4815\n",
      "Epoch 191/250\n",
      "4750/4750 [==============================] - 0s 39us/sample - loss: 1.3107\n",
      "Epoch 192/250\n",
      "4750/4750 [==============================] - 0s 36us/sample - loss: 1.3379\n",
      "Epoch 193/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.3852\n",
      "Epoch 194/250\n",
      "4750/4750 [==============================] - 0s 29us/sample - loss: 1.2609\n",
      "Epoch 195/250\n",
      "4750/4750 [==============================] - 0s 50us/sample - loss: 1.1717\n",
      "Epoch 196/250\n",
      "4750/4750 [==============================] - 0s 42us/sample - loss: 1.2000\n",
      "Epoch 197/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 6.0561\n",
      "Epoch 198/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 1.0553\n",
      "Epoch 199/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.4639\n",
      "Epoch 200/250\n",
      "4750/4750 [==============================] - 0s 53us/sample - loss: 1.2088\n",
      "Epoch 201/250\n",
      "4750/4750 [==============================] - 0s 44us/sample - loss: 1.4531\n",
      "Epoch 202/250\n",
      "4750/4750 [==============================] - 0s 40us/sample - loss: 1.5144\n",
      "Epoch 203/250\n",
      "4750/4750 [==============================] - 0s 48us/sample - loss: 1.4413\n",
      "Epoch 204/250\n",
      "4750/4750 [==============================] - 0s 43us/sample - loss: 1.1593\n",
      "Epoch 205/250\n",
      "4750/4750 [==============================] - 0s 47us/sample - loss: 1.3435\n",
      "Epoch 206/250\n",
      "4750/4750 [==============================] - 0s 41us/sample - loss: 1.1152\n",
      "Epoch 207/250\n",
      "4750/4750 [==============================] - 0s 38us/sample - loss: 1.1494\n",
      "Epoch 208/250\n",
      "4750/4750 [==============================] - 0s 39us/sample - loss: 3.8415\n",
      "Epoch 209/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.2819\n",
      "Epoch 210/250\n",
      "4750/4750 [==============================] - 0s 41us/sample - loss: 1.2647\n",
      "Epoch 211/250\n",
      "4750/4750 [==============================] - 0s 43us/sample - loss: 1.2058\n",
      "Epoch 212/250\n",
      "4750/4750 [==============================] - 0s 36us/sample - loss: 1.6259\n",
      "Epoch 213/250\n",
      "4750/4750 [==============================] - 0s 41us/sample - loss: 1.1919\n",
      "Epoch 214/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.2242\n",
      "Epoch 215/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.3367\n",
      "Epoch 216/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 4.1799\n",
      "Epoch 217/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.2787\n",
      "Epoch 218/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.2416\n",
      "Epoch 219/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 2.0993\n",
      "Epoch 220/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 3.2954\n",
      "Epoch 221/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.0358\n",
      "Epoch 222/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.1162\n",
      "Epoch 223/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.3218\n",
      "Epoch 224/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 1.1513\n",
      "Epoch 225/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 1.4299\n",
      "Epoch 226/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.7021\n",
      "Epoch 227/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.2165\n",
      "Epoch 228/250\n",
      "4750/4750 [==============================] - 0s 38us/sample - loss: 1.4223\n",
      "Epoch 229/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.8347\n",
      "Epoch 230/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.5000\n",
      "Epoch 231/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.4531\n",
      "Epoch 232/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.0932\n",
      "Epoch 233/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.0927\n",
      "Epoch 234/250\n",
      "4750/4750 [==============================] - 0s 30us/sample - loss: 1.0769\n",
      "Epoch 235/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.1404\n",
      "Epoch 236/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 1.1960\n",
      "Epoch 237/250\n",
      "4750/4750 [==============================] - 0s 36us/sample - loss: 1.1128\n",
      "Epoch 238/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 1.1912\n",
      "Epoch 239/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.0543\n",
      "Epoch 240/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.3428\n",
      "Epoch 241/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.0196\n",
      "Epoch 242/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.4469\n",
      "Epoch 243/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.0714\n",
      "Epoch 244/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.2227\n",
      "Epoch 245/250\n",
      "4750/4750 [==============================] - 0s 35us/sample - loss: 1.3121\n",
      "Epoch 246/250\n",
      "4750/4750 [==============================] - 0s 31us/sample - loss: 1.1067\n",
      "Epoch 247/250\n",
      "4750/4750 [==============================] - 0s 33us/sample - loss: 1.2114\n",
      "Epoch 248/250\n",
      "4750/4750 [==============================] - 0s 34us/sample - loss: 1.4416\n",
      "Epoch 249/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 2.1154\n",
      "Epoch 250/250\n",
      "4750/4750 [==============================] - 0s 32us/sample - loss: 1.2151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x285b508a748>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "predtf = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "predtf = list(chain(*predtf))\n",
    "predtf = np.array(predtf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.257847 , 4.6639876, 1.3026108, ..., 4.6456866, 4.5599093,\n",
       "       4.1641645], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfmae=mean_absolute_error(y_test, predtf).round(3)\n",
    "tfmsqe=mean_squared_error(y_test, predtf)\n",
    "tfrms = sqrt(mean_squared_error(y_test, predtf))\n",
    "tfcorr, _ = pearsonr(predtf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN\n",
      "Pearsons correlation: 0.788\n",
      "Mean Absolute Error: 0.671\n",
      "Mean Squre Root Error: 0.831\n",
      "Root Mean Squre Error: 0.912\n"
     ]
    }
   ],
   "source": [
    "print('ANN')\n",
    "print('Pearsons correlation: %.3f' % tfcorr)\n",
    "print('Mean Absolute Error: %.3f'%tfmae)\n",
    "print('Mean Squre Root Error: %.3f'%tfmsqe)\n",
    "print('Root Mean Squre Error: %.3f'%tfrms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Pearsons correlation: 0.954\n",
      "Mean Absolute Error: 0.286\n",
      "Mean Squre Root Error: 0.217\n",
      "Root Mean Squre Error: 0.466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfc = RandomForestRegressor(n_estimators=600)\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "rfpred = rfc.predict(X_test)\n",
    "rfmae=mean_absolute_error(y_test, rfpred).round(3)\n",
    "rfmsqe=mean_squared_error(y_test, rfpred)\n",
    "rfrms = sqrt(mean_squared_error(y_test, rfpred))\n",
    "rfcorr, _ = pearsonr(rfpred, y_test)\n",
    "print('Random Forest')\n",
    "print('Pearsons correlation: %.3f' % rfcorr)\n",
    "print('Mean Absolute Error: %.3f'%rfmae)\n",
    "print('Mean Squre Root Error: %.3f'%rfmsqe)\n",
    "print('Root Mean Squre Error: %.3f'%rfrms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Correlation Coefficient ')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrobjects = ('LR', 'DT', 'SVM', 'ANN','RF')\n",
    "y_pos = np.arange(len(corrobjects))\n",
    "corrperformance = [lmcorr,dtrcorr,svmcorr,tfcorr,rfcorr]\n",
    "plt.bar(y_pos, corrperformance, align='center',)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('corr value')\n",
    "plt.title('Correlation Coefficient ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mean Abs Error ')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "maeobjects = ('LR', 'RF', 'SVM', 'ANN','RF')\n",
    "y_pos = np.arange(len(maeobjects))\n",
    "maeperformance = [lmmae,rfmae,svmmae,tfmae,rfmae]\n",
    "plt.bar(y_pos, maeperformance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('mae')\n",
    "plt.title('Mean Abs Error ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mean sqrt Error ')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "msqrtobjects = ('LR', 'RF', 'SVM', 'ANN','RF')\n",
    "y_pos = np.arange(len(msqrtobjects))\n",
    "msqrtperformance = [lmmsqe,rfmsqe,svmmsqe,tfmsqe,rfmsqe]\n",
    "plt.bar(y_pos, msqrtperformance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('MSRE')\n",
    "plt.title('Mean sqrt Error ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Root Mean sqrt Error ')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmsqrtobjects = ('LR', 'RF', 'SVM', 'ANN','RF')\n",
    "y_pos = np.arange(len(rmsqrtobjects))\n",
    "rmsqrtperformance = [lmrms,rfrms,svmrms,tfrms,rfrms]\n",
    "plt.bar(y_pos, rmsqrtperformance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('RMS')\n",
    "plt.title('Root Mean sqrt Error ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest gives the best result with highest Correlation Coefficient and less errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
